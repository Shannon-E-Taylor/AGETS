{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc08f998",
   "metadata": {},
   "source": [
    "# MCMC Inference with AGETs\n",
    "\n",
    "This code shows how to use the AGETs inferred in the Notebook *Creating Approximated Gene Expression Trajectories (AGETs)* in an MCMC approach to infer GRN parameters. The AGETs contain a target gene expression for the Tbox genes that can be fit to. It also contains initial conditions (Tbox expression at the start) and boundary conditions (Wnt and FGF expression over time). For the inference, we only use a subset of all 1903 AGETs because of computation time. Only AGETs that are observed from start to end of the movie are used (longest AGETs), to minimize the influence of the initial conditions on the whole simulated expression. A randomly chosen subset of these longest AGETs are saved in the file *List_of_100_cell_tracks.txt*. For the following inference, 10 of these AGETs where chosen semi-randomly, meaning that they where chosen to approximately represent the whole region of interest in the PSM. Practically that meant, that the first 10 AGETs did not fulfill that criterion by visual inspection and the second 10 AGETs did. Therefore, AGETs 10-19 were used. In the code, Tbxta is referred to as g1, Tbx16 is referred to as g2 and Tbx24 is referred to as g3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a4362",
   "metadata": {},
   "source": [
    "## Define simulator\n",
    "\n",
    "In the following, a simulator class *Simulate_on_tracks* is defined. As indicated by the file name, tracks and AGETs are used interchangeably in the code. As explained in the paper, the simulator takes as input a set of 24 parameters describing the GRN and use ODEs with the initial and boundary conditions from the AGETs to simulate gene expression for the chosen 10 AGETs. The simulator class is then used in the following MCMC inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702aeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.integrate import odeint\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7200bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulator class \n",
    "\n",
    "class Simulate_on_tracks:\n",
    "    '''\n",
    "    The simulator takes as input a set of 24 parameters describing the GRN \n",
    "    and uses ODEs with the initial and boundary conditions from the AGETs to \n",
    "    simulate gene expression for the chosen 10 AGETs. The simulated gene expression\n",
    "    is then added to the AGET, so that the AGET includes the original target as well \n",
    "    as the simulated gene expression.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, parameters):\n",
    "        self.params = parameters\n",
    "        with open(\"Dependencies_simulator/List_of_100_cell_tracks.txt\", \"rb\") as fp:   \n",
    "            self.List_of_100_cell_tracks = pickle.load(fp)[10:20] # Load the chosen 10 AGETs\n",
    "\n",
    "    def simulation(self):\n",
    "        params = self.params\n",
    "\n",
    "        # Define helper functions for ODEs, see paper explanation of the ODEs\n",
    "        def g(x): \n",
    "            return 0.5 * ((x / np.sqrt(x ** 2 + 1)) + 1)\n",
    "        def PSH(s, t, B1, B2):\n",
    "            B = [B1, B2]\n",
    "            W = np.array(\n",
    "                [\n",
    "                    [params[0], params[1], params[2]],\n",
    "                    [params[3], params[4], params[5]],\n",
    "                    [params[6], params[7], params[8]],\n",
    "                ]\n",
    "            )\n",
    "            E = np.array(\n",
    "                [[params[18], params[17]], [params[19], params[15]], [params[20], params[16]]]\n",
    "            )\n",
    "            R = [params[9], params[10], params[11]]\n",
    "            lmd = [params[12], params[13], params[14]]\n",
    "            h = [params[21], params[22], params[23]]\n",
    "            u = np.array(\n",
    "                [\n",
    "                    W[0].dot(s) + E[0].dot(B) + h[0],\n",
    "                    W[1].dot(s) + E[1].dot(B) + h[1],\n",
    "                    W[2].dot(s) + E[2].dot(B) + h[2],\n",
    "                ]\n",
    "            )\n",
    "            d_tbxta_dt = R[0] * g(u[0]) - lmd[0] * s[0]\n",
    "            d_tbx16_dt = R[1] * g(u[1]) - lmd[1] * s[1]\n",
    "            d_tbx24_dt = R[2] * g(u[2]) - lmd[2] * s[2]\n",
    "            dsdt = [d_tbxta_dt, d_tbx16_dt, d_tbx24_dt]\n",
    "            return dsdt\n",
    "        df_out = []\n",
    "        \n",
    "        # Iterate through celltracks (AGETs)\n",
    "        for i_celltrack in range(len(self.list_of_cell_tracks)):\n",
    "            df_celltrack = self.list_of_cell_tracks[i_celltrack]\n",
    "            df_celltrack['Time_nPSM'] = np.nan\n",
    "            df_celltrack.Time_nPSM = df_celltrack.Time*90/3600/3 # Add biological time, used later\n",
    "            df_celltrack['g1_sim'] = df_celltrack['g2_sim'] = df_celltrack['g3_sim'] = np.nan # add empty columns for simulated gene expression \n",
    "            df_celltrack.loc[0, ['g1_sim', 'g2_sim', 'g3_sim']] = df_celltrack.loc[0, ['g1', 'g2', 'g3']].values # initial conditions are the same\n",
    "            max_time = np.max(df_celltrack.Time)\n",
    "            for index, row in df_celltrack.loc[0:df_celltrack.shape[0], :].iterrows(): # stepwise integration until last time point is reached\n",
    "                if row['Time'] != max_time: \n",
    "                    B1 = row['Wnt']\n",
    "                    B2 = row['FGF']\n",
    "                    count_timesteps_between = df_celltrack.Time[index+1] - df_celltrack.Time[index] # number of time steps between observations, sometimes an observation at a specific time is missing\n",
    "                    t_interval = np.linspace(df_celltrack.Time_nPSM[index], df_celltrack.Time_nPSM[index+1], 10*int(count_timesteps_between))\n",
    "                    s0 = row[['g1_sim', 'g2_sim', 'g3_sim']]\n",
    "                    s = odeint(PSH, s0, t_interval, args=(B1, B2))\n",
    "                    df_celltrack.loc[index+1, ['g1_sim', 'g2_sim', 'g3_sim']] = s[-1]\n",
    "            df_out.append(df_celltrack) # append AGET with the simulated expression to the output list\n",
    "        return df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5deada3",
   "metadata": {},
   "source": [
    "## Define MCMC building blocks and run MCMC\n",
    "\n",
    "For the MCMC, a logprior function consisting of a Gaussian loglikelihood function and a logprior function is needed. For further guidance, a look at the tutorials for the used MCMC Python implementation [emcee](https://emcee.readthedocs.io/en/stable/) is recommended. The uniform prior was chosen based on biological intuition for reasonable values for the parameters. The MCMC inference should be run on a powerful computer. The computation time can be reduced by using more cores as the computation can be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad2019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 CPUs\n"
     ]
    }
   ],
   "source": [
    "# MCMC\n",
    "\n",
    "def loglikelihood(theta):\n",
    "    sim = Simulate_on_tracks(parameters=theta) # Simulate gene expression for parameters theta on above defined 10 AGETs\n",
    "    data = sim.simulation() \n",
    "    g_sim_g1 = data[0].g1_sim.values # simulated expression for Tbxta for AGET 1\n",
    "    g_target_g1 = data[0].g1.values # target expression for Tbxta from AGET 1\n",
    "    g_sim_g2 = data[0].g2_sim.values\n",
    "    g_target_g2 = data[0].g2.values\n",
    "    g_sim_g3 = data[0].g3_sim.values\n",
    "    g_target_g3 = data[0].g3.values\n",
    "    for i_ncelltracks in range(1, len(data)): # combine the values for each gene for the 10 AGETs, used for ll calulation below\n",
    "        g_sim_g1 = np.append(g_sim_g1, data[i_ncelltracks].g1_sim.values) \n",
    "        g_target_g1 = np.append(g_target_g1, data[i_ncelltracks].g1.values)\n",
    "        g_sim_g2 = np.append(g_sim_g2, data[i_ncelltracks].g2_sim.values)\n",
    "        g_target_g2 = np.append(g_target_g2, data[i_ncelltracks].g2.values)\n",
    "        g_sim_g3 = np.append(g_sim_g3, data[i_ncelltracks].g3_sim.values)\n",
    "        g_target_g3 = np.append(g_target_g3, data[i_ncelltracks].g3.values)\n",
    "    # The likelihood is calculated based on the difference between simulated and target expression\n",
    "    # The closer the simulation is to the target expression, the higher the likelihood\n",
    "    ll1 = -0.5 * np.sum(((g_sim_g1 - g_target_g1)/0.2)**2) # SD=0.2 found by testing different SDs and looking what works best\n",
    "    ll2 = -0.5 * np.sum(((g_sim_g2 - g_target_g2)/0.2)**2) # SD=0.2 found by testing different SDs and looking what works best\n",
    "    ll3 = -0.5 * np.sum(((g_sim_g3 - g_target_g3)/0.1)**2) # SD=0.1 found by testing different SDs and looking what works best\n",
    "    return ll1 + ll2 + ll3\n",
    "\n",
    "def logprior(theta): # prior was chosen based on biological intuition for the parameters\n",
    "    # This is a uniform prior, meaning that all values inside the prior have the same probability and all values outside\n",
    "    # of the prior have probability 0 \n",
    "    W11, W12, W13, W21, W22, W23, W31, W32, W33, r1, r2, r3, lmd1, lmd2, lmd3, f1, f2, f3, w1, w2, w3, H1, H2, H3 = theta\n",
    "    if 0 < W11 < 20 and \\\n",
    "       -20  < W12 < 20  and \\\n",
    "       -20  < W13 < 20  and \\\n",
    "       -20  < W21 < 20  and \\\n",
    "       0  < W22 < 20  and \\\n",
    "       -20  < W23 < 20  and \\\n",
    "       -20 < W31 < 20 and \\\n",
    "       -20  < W32 < 20  and \\\n",
    "       0  < W33 < 30  and \\\n",
    "       0 < r1 < 20 and \\\n",
    "       0 < r2 < 20 and \\\n",
    "       0 < r3 < 20 and \\\n",
    "       0 < lmd1 < 10 and \\\n",
    "       0 < lmd2 < 10 and \\\n",
    "       0 < lmd3 < 10 and \\\n",
    "       -30 < f1 < 30 and \\\n",
    "       -30 < f2 < 30 and\\\n",
    "       -30 < f3 < 30 and\\\n",
    "       0 < w1 < 30 and \\\n",
    "       -30 < w2 < 30 and \\\n",
    "       -30 < w3 < 30 and \\\n",
    "       -30 < H1 < 30 and \\\n",
    "       -30 < H2 < 30 and \\\n",
    "       -30 < H3 < 30:\n",
    "        lp = 0.\n",
    "    else:\n",
    "        lp = -np.inf\n",
    "    return lp\n",
    "\n",
    "def logposterior(theta):\n",
    "    lp = logprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + loglikelihood(theta)\n",
    "\n",
    "# Number of walkers, the MCMC method used uses multiple walkers. See the emcee documentation for more information.\n",
    "# We used 70 walkers, but the documentation recommended to use several hundreds. In our case, this didn't lead \n",
    "# to better results and was therefore set to 70 to reduce computation time. With 20 cores, 70 walkers, 50000 steps and\n",
    "# 10 AGETs, it took a approximately 3 days to run the MCMC.\n",
    "nwalkers = 70 \n",
    "\n",
    "# Initial (nwalkers) points, starting points for the walkers\n",
    "W11_ini = np.random.uniform(0,20, nwalkers) \n",
    "W12_ini = np.random.uniform(-20,20, nwalkers) \n",
    "W13_ini = np.random.uniform(-20,20, nwalkers)\n",
    "W21_ini = np.random.uniform(-20,20, nwalkers)\n",
    "W22_ini = np.random.uniform(0,20, nwalkers) \n",
    "W23_ini = np.random.uniform(-20,20, nwalkers)\n",
    "W31_ini = np.random.uniform(-20,20, nwalkers)\n",
    "W32_ini = np.random.uniform(-20,20, nwalkers)\n",
    "W33_ini = np.random.uniform(0,30, nwalkers)\n",
    "r1_ini = np.random.uniform(0, 20, nwalkers)\n",
    "r2_ini = np.random.uniform(0, 20, nwalkers)\n",
    "r3_ini = np.random.uniform(0, 20, nwalkers)\n",
    "lmd1_ini = np.random.uniform(0, 10, nwalkers) \n",
    "lmd2_ini = np.random.uniform(0, 10, nwalkers)\n",
    "lmd3_ini = np.random.uniform(0, 10, nwalkers)\n",
    "f1_ini = np.random.uniform(-30,30, nwalkers)\n",
    "f2_ini = np.random.uniform(-30,30, nwalkers)\n",
    "f3_ini = np.random.uniform(-30,30, nwalkers)\n",
    "w1_ini = np.random.uniform(0,30, nwalkers)\n",
    "w2_ini = np.random.uniform(-30,30, nwalkers)\n",
    "w3_ini = np.random.uniform(-30,30, nwalkers)\n",
    "H1_ini = np.random.uniform(-30,30, nwalkers)\n",
    "H2_ini = np.random.uniform(-30,30, nwalkers)\n",
    "H3_ini = np.random.uniform(-30,30, nwalkers)\n",
    "\n",
    "# Combine initial points\n",
    "p0 = np.array([W11_ini, W12_ini, W13_ini, \\\n",
    "                       W21_ini, W22_ini, W23_ini,\\\n",
    "                       W31_ini, W32_ini, W33_ini,\\\n",
    "                       r1_ini, r2_ini, r3_ini,\\\n",
    "                       lmd1_ini, lmd2_ini, lmd3_ini,\\\n",
    "                       f1_ini, f2_ini,f3_ini, w1_ini, w2_ini,\\\n",
    "                       w3_ini, H1_ini, H2_ini, H3_ini ]).T\n",
    "\n",
    "# Define number of steps for the MCMC inference\n",
    "Nsamples = 50000\n",
    "ndim = p0.shape[1] # needed below\n",
    "i_run = 1 # if running multiple times, i_run is used for the name of the saved results\n",
    "ncpu = cpu_count() # finde number of available CPUs for parallel processing\n",
    "print(\"{0} CPUs\".format(ncpu))\n",
    "\n",
    "# Run MCMC (this takes time)\n",
    "with Pool(ncpu) as pool: \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, logposterior, pool=pool)\n",
    "    start = time.time()\n",
    "    sampler.run_mcmc(p0, Nsamples, progress=True)\n",
    "    end = time.time()\n",
    "    multi_time = end - start\n",
    "    print(\"Multiprocessing took {0:.1f} seconds\".format(multi_time))\n",
    "\n",
    "    \n",
    "# Save samples    \n",
    "samples = sampler.get_chain(flat=True)\n",
    "print('samples')\n",
    "print(samples.shape)\n",
    "print(type(samples))\n",
    "print(' ')\n",
    "with open(f\"samples_run{i_run}.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(samples, fp)\n",
    "\n",
    "# Save log probabilities\n",
    "log_probs = sampler.flatlnprobability\n",
    "print('log_probs')\n",
    "print(log_probs.shape)\n",
    "print(type(log_probs))\n",
    "print(' ')\n",
    "with open(f\"log_probs_run{i_run}.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(log_probs, fp)\n",
    "\n",
    "# Save MAP params (params with highest posterior probability)\n",
    "map_params = samples[np.argmax(sampler.flatlnprobability)]\n",
    "print('map_params')\n",
    "print(map_params.shape)\n",
    "print(type(map_params))\n",
    "print(' ')\n",
    "with open(f\"map_params_run{i_run}.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(map_params, fp)\n",
    "\n",
    "# Save acceptance fraction: MCMC diagnostic\n",
    "acceptance_fraction = sampler.acceptance_fraction\n",
    "print('acceptance_fraction')\n",
    "print(acceptance_fraction.shape)\n",
    "print(type(acceptance_fraction))\n",
    "print(' ')\n",
    "with open(f\"acceptance_fraction_run{i_run}.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(acceptance_fraction, fp)\n",
    "\n",
    "# Save autocorrelation time: MCMC diagnostic\n",
    "autocorr_time = sampler.get_autocorr_time(quiet=True)\n",
    "print('autocorr_time')\n",
    "print(autocorr_time.shape)\n",
    "print(type(autocorr_time))\n",
    "print(' ')\n",
    "with open(f\"autocorr_time_run{i_run}.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(autocorr_time, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d106bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
